---
layout: post
title: Systematic Trading Strategy based on Image Processing and Temporal Convolutional Networks
---

## Motivation
The majority of work done in classification of price moves using machine learning models use raw data even for an image classification algorithm like Convolutional Neural Network (CNN). However to highly dynamic and non-stationarity nature of stock prices these models either fail to capture any meaningful patterns or highly overfit to the training data (which is exacerbated for Deep Learning Models). Generally manual traders tend to looks the historical plot of the time series along with the assistance of technical indicators to assess the trend of the market going forward, these traders either look at specific patterns like EMA/DMA crossovers or something more intricate like evolution of these technical indicators in conjunction with the actual price moves over time. Using traditional machine learning techniques one can encode specific patters as features, but  modelling the intricate movement of the price becomes very challenging. Taking inspiration from above point in this post we devise a systematic trading that will convert the raw price data and technical indicators for a given lookback into a static image along (with approriate labels), process it and feed it to the Temporal Convoluational Network that will classify the trend over next N days (i.e. *long*, *short* or *neutral*). The two key advantages of above approach is that, 
-   It transforms the raw data into a static image which makes the model less suscptible to non-stationarity nature of the financial time series.
-   Since the information is in the form of an image, the convolutional filters can fine tune its weights via backpropogation to find areas of high information density

## Temporal Convolutional Networks (TCN)
TCNs offer a new approach to sequence modelling and based on the work done by Bai et al. [2018][1], TCNs exhibits longer memory and tends to outperform LSTM, RNNs, and LSTM-CNN models on sequence modelling and image classification tasks like sequential MNIST, P-MNIST, Polyphonic music, Word-level language modeling etc. TCN consists of residual blocks which usually contains two layers of dilated causal convolution and activation functions, the dilated convolutions enables the output to represnet a wider range of the inputs thus expanding its receptive field. This feature also makes TCN approach ideal for video classification, where the a video represents a sequence of images. In our framework, we will represent the sequence of price images as a video and feed it to TCN for the classification task. Our TCN model  uses ***Many-to-One*** mapping to classify the image, i.e. many input images are used as an input to classify one output. See the figure (from [1]) for more detailed architecture of TCN.

<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103604891-54f64a80-4ee0-11eb-8556-b1e094161b74.png", height="250"></p>

## Approach
Our approach involves building all the components of this framework from the ground up, which involves ***data generation, data labeling, data preprocessing, Model Training and Predictions***, and finally ***trade decision module*** for taking final trade decision. To generate the dataset we first generate price based technical indicators and plot them along with the closing price as png images using ***plotly***[2]. The output labels are generated based on subsequent price changes. Once the dataset is generated (more information is following sections), we create a tensor containing 10 consecutive images with the output label of the tensor being the output label of the most recent image in the new tensor. These input tensors are then passed on to the TCN model that generates the predicted probability distributions of the output classes. These probabilities are then used by the trade decision module to either take a ’buy’, ’sell’, or ’neutral’ stand in the market.

To evaluate the merits of our approach we benchmark the performance to standard baseline classifiers. The baselines used in this paper are CNNs, SVMs, and Random Forests (RFs). Since SVMs and RFs are generally not suitable for image data, we feed them the same features in raw numerical form. The evaluation procedure compares both the classification metrics as well as the overall profit/loss generated by each baseline model to the TCN model.

## Dataset Generation and Preprocessing
The raw prices used in this paper contains SPY ETF Prices from Jan, 2013 to Nov, 2020. The financial price features to be used along with raw prices are Exponential Moving Average with lookback of 10 and 30 days, and Bollinger Bands with lookback of 28 days, and standard deviation of 2σ. Once we have the raw prices and financial features we generate the image with a lookback period of 20 days, with a rolling window of 1 day i.e. we plot the first image containing the data for 0-20 days, the second image containing the data for 1-21 days, and so on. With this scheme we generate around 1900 images overall, which includes training, validation and test sets.

Once we have the raw input images we need to generate corresponding labels so that we can train it on a classification model, the labeling scheme either labels the images as ’buy’, ’sell’ or neutral’ based on percentage price move(threshold) over the next 10 days. If the percentage move is above positive threshold the image is labelled as ’buy’, else if its below the negative threshold we label the image as ’sell’, else the image is labelled as ’neutral’. This procedure can be formalized as


<!-- $ Label_{i}=\left\{
                \begin{array}{ll}
                  buy (1) \; \; \; if \;  price_{t+10}/price_{t+1} -1 > thresh \\
                  sell(-1) \; \; \; elif \; price_{t+10}/price_{t+1} -1 < -thresh \\
                  neutral(0) \; \; \; otherwise \\
                \end{array}
              \right. $ --> <img style="transform: translateY(0.25em);" src="../svg/m96wZGMT6P.svg"/>


The threshold used in our case is ***0.5%***. The train, validation and test sets are separated chronologically as we want to maintain the temporal integrity of the dataset. The training set contains all the tensors from Jan, 2013 to Dec 2017, validation set containing tensors from Jan, 2018 to Dec, 2018, and test set from Jan, 2019 to Nov, 2020. The denser white line represents the actual prices and thinner colored lines represent the technical indicators for the same time period

<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103606736-2dee4780-4ee5-11eb-9723-8395fde9e72e.png", height="250"></p>

We wanted to reduce the resolution of the image to ensure the training procedure did not get clogged, at the same time ensuring all information is retained. To achieve this we resized the cropped image to 128x128 RGB image using openCV2. The pixel intensities were also normalized to remove any spikes in the image pixels, which is generally recommended for stable model training.

## Model Pipeline
The plot below shows the general flow of our framework, the first 2 blocks are responsible for data generation and preprocessing steps. The third part of the model pipeline is responsible for creating a tensor of 10 consecutive images, which basically represents a sequence of images. 

<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103606858-81609580-4ee5-11eb-8269-88fa1cb122f2.png", height="200"></p>

The TCN classifier then takes in the tensor of 10 images and generates a probability distribution over all three output classes. The trade decision module then takes buy, sell, or neutral trade decision based on this probability distribution. ***Currently in this version of the project, we use a simple ARGMAX formula which is standard practice in Machine Learning, however more esoteric rules can also be used in this module which adds additional flexibility to the proposed framework.***

## Results
### Training Specs and Classification Results
The TCN classifier in our approach is trained with the following hyper-parameters
``` NUM TCN Filters = 64, Kernal Size = 3, learning rate = 10e-4,Optimizer = ADAM, NUM epochs = 300, Batch Normalization = True. ```
Based on the loss plot in Figure below, we observe that the training procedure is fairly stable and the loss minimization maxes out at around epoch = 270, a similar pattern can be observed with the accuracy plot as well.

<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103607500-11530f00-4ee7-11eb-993b-55c903987f40.png", height="200"></p>

The overall test set accuracy obtained on this multiclass classification task is ***52%***, and the confusion matrix along with precision-recall curves are shown below.
<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103608116-925ed600-4ee8-11eb-820c-507001b84c9b.png", height="120"></p>

<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103608324-1c0ea380-4ee9-11eb-9014-0656f80c78e3.png", height="300"></p>

From the above classification metric the performance on the ***buy*** class just pops out, the f-1 score as well as the accuracy on the buy lable are much higher than ***sell*** and ***neutral*** classes. This primarily down to the fact that the dataset contains a lot more buy labels than sell and neutral labels, since equity markets especially SPY over past few years have strongly trended positive.
``` One way to ameliorate this effect is to make balanced classes in the training set (which is not done in this version of the framework), which will make the training more stable and balanced.```
### Baseline classification results
The table below compares the performance of TCN classifier against other baselibe classifiers like CNN, RF and SVM. TCN outperforms other baseline classifiers on all classification metrics except precision. The high precision exhibited by vanilla classifiers like SVM and RFs is down the fact that these models tend to overclassify one class, which in this case was the ’buy’ class. On closer inspection we found that both SVM and RFs failed to predict any ’neutral’ class in the test set. The TCN also exhibited highest Jaccard similarity metric, which indicates that it closely predicts the output classes.

<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103721930-df03e900-4f9c-11eb-9744-903950ad8b11.png", height="200"></p>

### Strategy Return metrics
To compute actual returns generated by each classifier, we take ***argmax*** of the output probability distribution and take bet in its direction, i.e. if highest probability is given to buy signal we go long in SPY ETF. On the execution side,

*   Slippages for each side trade are assumed to be 1.5 basis points or 0.00015
*   The signals are generated on closing prices, and the decision to enter the trades are taken at the market open the next day

Based on above assumptions around execution, the return metrics are shown below
<p align="center"><img src="https://user-images.githubusercontent.com/71300644/103723263-ad405180-4f9f-11eb-822f-721a9901a287.png", height="400"></p>
Based on the performance plot as well as performance metrics, TCN vastly outperforms other baseline models

## Conclusion and Future Work
This post introduced an innovative solution to an algorithmic trading system built on the concepts of computer vision, the experiments also indicated the power of using price images and TCN model for time-series classification problems. The outperformance of the CNN model over RF and SVM models on the classification tasks exhibits the merit of using images of prices over raw data in image classification models. The research done in this post is pretty preliminary which incudes image preprocessing and filtering techniques, the next steps can invlove

```
1. Uisng higher resolution images which will include more information and may improve the performance
2. Include additional information in the images including non-price/alternative data of same frequency
3. Use state-of-the-art filtering techniques as a preprocessing step to remove redundant information
4. The threshold currently used uses a fixed precentage move, there's a lot of literature on adpative labelling techniques which can be used here to label the price images
5. The trade decision model in this post used a basic argmax function, an additional layer of complexity can be added on top of it to further optimize the trading signals
6. Class imbalance was one of the issues in this framework as highlighted in this post. Training with balanced classes may improve the performance of the TCN model
```

The link to the github repository will be added shortly

## References ##
    1. Bai, S., Kolter, J. Z. & Koltun, V. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271 (2018)
    2. Plotly Python https://plotly.com/python/